# AWS S3 Integration Guide

## üéØ T·ªïng Quan

AWS S3 **KH√îNG THAY TH·∫æ** PostgreSQL. Ch√∫ng ho·∫°t ƒë·ªông c√πng nhau:

- **PostgreSQL:** L∆∞u tr·ªØ d·ªØ li·ªáu c√≥ c·∫•u tr√∫c (problems, solved status, etc.)
- **AWS S3:** L∆∞u tr·ªØ files (backups, images, documents)

## üèóÔ∏è Ki·∫øn Tr√∫c

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application                                             ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ PostgreSQL  ‚îÇ ‚Üê‚îÄ‚îÄ Queries ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ  Node.js    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Database   ‚îÇ                  ‚îÇ   Backend   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                           ‚îÇ            ‚îÇ
‚îÇ                                           ‚îÇ Upload     ‚îÇ
‚îÇ                                           ‚Üì            ‚îÇ
‚îÇ                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ                                    ‚îÇ   AWS S3    ‚îÇ     ‚îÇ
‚îÇ                                    ‚îÇ   Bucket    ‚îÇ     ‚îÇ
‚îÇ                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì¶ Use Cases

### 1. Backup Database L√™n S3 (Recommended)

**L·ª£i √≠ch:**
- ‚úÖ B·∫£o v·ªá d·ªØ li·ªáu kh·ªèi m·∫•t m√°y local
- ‚úÖ Disaster recovery
- ‚úÖ Chia s·∫ª backup v·ªõi team
- ‚úÖ T·ª± ƒë·ªông retention policy

**Setup:**

#### B∆∞·ªõc 1: C√†i AWS SDK

```bash
npm install @aws-sdk/client-s3
```

#### B∆∞·ªõc 2: C·∫•u H√¨nh AWS Credentials

**File:** `.env`
```env
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
AWS_S3_BUCKET=leetcode-backups
```

#### B∆∞·ªõc 3: T·∫°o Script Backup L√™n S3

**File:** `server/scripts/backupToS3.js`

```javascript
const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');
const { exec } = require('child_process');
const { promisify } = require('util');
const fs = require('fs');
const path = require('path');

const execAsync = promisify(exec);

async function backupToS3() {
  try {
    console.log('üîÑ Starting backup to S3...');
    
    // 1. Create local backup
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `backup_${timestamp}.sql`;
    const localPath = path.join(__dirname, '../../backups', filename);
    
    console.log('üíæ Creating local backup...');
    await execAsync(
      `docker exec leetcode-postgres pg_dump -U leetcodeuser leetcodepractice > ${localPath}`
    );
    
    // 2. Upload to S3
    console.log('‚òÅÔ∏è  Uploading to S3...');
    const s3Client = new S3Client({
      region: process.env.AWS_REGION,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
      }
    });
    
    const fileContent = fs.readFileSync(localPath);
    
    await s3Client.send(new PutObjectCommand({
      Bucket: process.env.AWS_S3_BUCKET,
      Key: `backups/${filename}`,
      Body: fileContent,
      ContentType: 'application/sql',
      Metadata: {
        'backup-date': new Date().toISOString(),
        'database': 'leetcodepractice'
      }
    }));
    
    const fileSizeMB = (fs.statSync(localPath).size / 1024 / 1024).toFixed(2);
    
    console.log('‚úÖ Backup uploaded to S3 successfully!');
    console.log(`üìä File: ${filename}`);
    console.log(`üìè Size: ${fileSizeMB} MB`);
    console.log(`ü™£ Bucket: ${process.env.AWS_S3_BUCKET}`);
    console.log(`üîó Key: backups/${filename}`);
    
    // Optional: Delete local backup after upload
    // fs.unlinkSync(localPath);
    
  } catch (error) {
    console.error('‚ùå Backup to S3 failed:', error);
    throw error;
  }
}

// Run if called directly
if (require.main === module) {
  backupToS3()
    .then(() => process.exit(0))
    .catch(() => process.exit(1));
}

module.exports = { backupToS3 };
```

#### B∆∞·ªõc 4: Ch·∫°y Backup

```bash
node server/scripts/backupToS3.js
```

### 2. Restore T·ª´ S3

**File:** `server/scripts/restoreFromS3.js`

```javascript
const { S3Client, GetObjectCommand, ListObjectsV2Command } = require('@aws-sdk/client-s3');
const { exec } = require('child_process');
const { promisify } = require('util');
const fs = require('fs');
const path = require('path');

const execAsync = promisify(exec);

async function listS3Backups() {
  const s3Client = new S3Client({
    region: process.env.AWS_REGION,
    credentials: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
    }
  });
  
  const response = await s3Client.send(new ListObjectsV2Command({
    Bucket: process.env.AWS_S3_BUCKET,
    Prefix: 'backups/'
  }));
  
  return response.Contents || [];
}

async function restoreFromS3(s3Key) {
  try {
    console.log('üîÑ Starting restore from S3...');
    
    // 1. Download from S3
    console.log('‚òÅÔ∏è  Downloading from S3...');
    const s3Client = new S3Client({
      region: process.env.AWS_REGION,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
      }
    });
    
    const response = await s3Client.send(new GetObjectCommand({
      Bucket: process.env.AWS_S3_BUCKET,
      Key: s3Key
    }));
    
    const filename = path.basename(s3Key);
    const localPath = path.join(__dirname, '../../backups', filename);
    
    // Convert stream to buffer
    const chunks = [];
    for await (const chunk of response.Body) {
      chunks.push(chunk);
    }
    const fileContent = Buffer.concat(chunks);
    
    fs.writeFileSync(localPath, fileContent);
    
    console.log('üíæ Downloaded to:', localPath);
    
    // 2. Restore to database
    console.log('üîÑ Restoring to database...');
    await execAsync(
      `docker exec -i leetcode-postgres psql -U leetcodeuser -d leetcodepractice < ${localPath}`
    );
    
    console.log('‚úÖ Restore completed successfully!');
    
  } catch (error) {
    console.error('‚ùå Restore from S3 failed:', error);
    throw error;
  }
}

module.exports = { listS3Backups, restoreFromS3 };
```

### 3. T·ª± ƒê·ªông Backup L√™n S3 H√†ng Ng√†y

**File:** `scripts/backup-to-s3.ps1`

```powershell
# Backup to S3 Script
$ErrorActionPreference = "Stop"

Write-Host "üîÑ Starting backup to S3..." -ForegroundColor Cyan

# Change to project directory
$SCRIPT_DIR = Split-Path -Parent $MyInvocation.MyCommand.Path
$PROJECT_DIR = Split-Path -Parent $SCRIPT_DIR
Set-Location $PROJECT_DIR

# Run backup script
node server/scripts/backupToS3.js

if ($LASTEXITCODE -eq 0) {
    Write-Host "‚úÖ Backup to S3 completed!" -ForegroundColor Green
} else {
    Write-Host "‚ùå Backup to S3 failed!" -ForegroundColor Red
    exit 1
}
```

**Setup Task Scheduler:**
- Gi·ªëng nh∆∞ backup local
- Ch·∫°y `scripts/backup-to-s3.ps1` thay v√¨ `scripts/backup.ps1`

## üîê Security Best Practices

### 1. S·ª≠ D·ª•ng IAM User Ri√™ng

T·∫°o IAM user ch·ªâ c√≥ quy·ªÅn S3:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::leetcode-backups",
        "arn:aws:s3:::leetcode-backups/*"
      ]
    }
  ]
}
```

### 2. Encrypt Backups

```javascript
await s3Client.send(new PutObjectCommand({
  Bucket: process.env.AWS_S3_BUCKET,
  Key: `backups/${filename}`,
  Body: fileContent,
  ServerSideEncryption: 'AES256' // ‚Üê Encrypt at rest
}));
```

### 3. Lifecycle Policy

T·ª± ƒë·ªông x√≥a backup c≈© sau 30 ng√†y:

```json
{
  "Rules": [
    {
      "Id": "DeleteOldBackups",
      "Status": "Enabled",
      "Prefix": "backups/",
      "Expiration": {
        "Days": 30
      }
    }
  ]
}
```

## üí∞ Chi Ph√≠

### S3 Pricing (us-east-1)

- **Storage:** $0.023/GB/month
- **PUT requests:** $0.005/1000 requests
- **GET requests:** $0.0004/1000 requests

**V√≠ d·ª•:**
- Backup size: 2 MB
- Backup frequency: Daily (30 backups/month)
- Total storage: 60 MB = 0.06 GB

**Chi ph√≠/th√°ng:**
- Storage: 0.06 GB √ó $0.023 = $0.00138
- PUT: 30 √ó $0.005/1000 = $0.00015
- **Total: ~$0.002/month** (g·∫ßn nh∆∞ mi·ªÖn ph√≠!)

## üéØ K·∫øt Lu·∫≠n

### PostgreSQL vs S3

| Feature | PostgreSQL | AWS S3 |
|---------|-----------|--------|
| **M·ª•c ƒë√≠ch** | Structured data | Files/Objects |
| **D√πng cho** | Problems, users, reviews | Backups, images, docs |
| **Query** | SQL | HTTP API |
| **Cost** | Fixed (container) | Pay per use |
| **Backup** | pg_dump | Upload files |

### Recommendation

**Cho project c·ªßa b·∫°n:**

1. ‚úÖ **Gi·ªØ PostgreSQL** - Cho database ch√≠nh
2. ‚úÖ **Th√™m S3** - Cho backup t·ª± ƒë·ªông l√™n cloud
3. ‚úÖ **Dual backup** - Local (nhanh) + S3 (an to√†n)

**Setup ƒë·ªÅ xu·∫•t:**
```
Daily backup:
‚îú‚îÄ Local backup (scripts/backup.ps1)
‚îî‚îÄ S3 backup (scripts/backup-to-s3.ps1)

Retention:
‚îú‚îÄ Local: 10 backups g·∫ßn nh·∫•t
‚îî‚îÄ S3: 30 ng√†y (lifecycle policy)
```

## üìö T√†i Li·ªáu Tham Kh·∫£o

- [AWS S3 Documentation](https://docs.aws.amazon.com/s3/)
- [AWS SDK for JavaScript v3](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/)
- [S3 Pricing](https://aws.amazon.com/s3/pricing/)
